# The Future of Work Is Context Engineering

**By Nick Holzherr, Founder and CEO of GitLaw**

**Publication Date**: [To be filled]  
**Publication**: [To be filled]  
**Status**: Published

---

Most organisations struggling with AI tools are not failing because the models are weak. 

They're failing because they still think of artificial intelligence as a plug-and-play widget – one that magically produces value without much thought given about how it's integrated into real work.

That's the real lesson distributed teams solved long before AI ever became mainstream: context matters more than proximity.

## Distributed teams solved the context problem before AI exposed it

Remote and async teams can't rely on informal chats, whiteboard sessions, or water-cooler conversations to transfer knowledge. Assumptions, guidelines, and decisions need to be written down, accessible, and traceable.

This isn't documentation for documentation's sake. It's the foundation of how work gets done in a distributed environment. Information is written down, work becomes clearer, and guesswork, ambiguity, and the silent assumptions are all reduced.

AI models don't have as much intuition as humans do, yet. They can't "fill in the blanks" the way people do. If you don't supply context, they invent it – which is how you end up with hallucinations and irrelevant results.

In-office teams often get away with weak context because informal conversations paper over the gaps. The information still exists, but it's trapped in people's heads. AI doesn't have that luxury. If you don't give it context, it simply doesn't have it.

## People don't fail with AI because models are weak

Most people who "fail" with AI don't fail because the models are bad. They fail because they're too lazy to provide sufficient context. A vague prompt translates into a vague response, and the user blames the tool.

That's backward. AI output quality is directly proportional to the quality of the context it either already has or receives. Give an AI model broad, shallow prompts, and you'll often get broad, shallow responses, no matter how sophisticated the model is. Often, the error rate is just high enough that editing the output becomes as tedious as doing the work yourself. Sometimes more so. 

The same thing happens with humans, but we are far more forgiving.  Imagine a new team member who knows nothing about your business, and whose output is mediocre in the first week. Most employers would defend that human vigorously, "it's just their first week! They need time to learn how we do things first". 

## The same problem exists with onboarding humans

I've been an advocate of distributed work for a long time. In 2016, years before COVID normalised it, we built a fully distributed team and scaled from two people in my bedroom to more than 120 people globally. 

I saw first-hand that the most common mistake companies make with remote workers is assuming they should "just get the work done." Compare that to how companies onboard in-office employees: Often a week of onboarding, dinners to embed culture, shadowing teammates, all sharing context about how decisions are made and what the work is. With contractors or remote hires, all of that is often skipped. Then leaders act surprised when outcomes disappoint. A contractor struggling with too little context is often not incompetent, but lacks context. AI is no different.

## The best outcomes come from deep context

The simplest way to improve AI output is to spend time writing context and asking an LLM to help refine it:, "What else should I add to my prompt to give me a better outcome", before running the final prompt.  That helps, but it's still "beginner level". 

The real step-change comes when you stop treating prompts as one-offs and start treating context as infrastructure. At GitLaw, we write specs for almost everything. Product behaviour, workflows, edge cases, assumptions. These specs live as Markdown files in a repository.

We're not alone, and it's often referred to as "spec-driven development" or SDD in short. Specs are written before code, in a format that LLMs can easily read. We structure them deliberately so that large language models can consume them effectively. When we ask questions like: "How should this feature work?", "What edge cases are missing?" or "Write the code for this component", we pass the relevant parts of the spec into the model. The difference is night and day.

Spec-driven workflows dramatically reduce rework, misalignment and silent assumptions.  Because ambiguity is surfaced early, before code is written, before work is duplicated, before opinions harden.

This approach applies far beyond engineering. We use it for legal and operational playbooks, hiring scorecards, marketing and sales material.  

## Your organisational memory is your key asset

When people talk about "AI context," they often imagine something magical or opaque. In practice, it's simpler. Context is just well-maintained artefacts. Specs, playbooks, and decision logs that are kept up to date reflect how you want work to actually be done and can be shared with humans or machines.

Models will continue to get better. Faster. Cheaper. More capable. The models are also very interchangeable most of the time. 
High-quality, structured, up-to-date context is expensive to create and maintain. And that's exactly why it matters.

The future of work isn't prompt engineering. It's context engineering.

The teams that win won't be the ones with the best models. They'll be the ones who know how to give them something worth working with.

---

## About the Author

**Nick Holzherr, Founder and CEO of GitLaw**

Nick Holzherr is a serial entrepreneur and CEO of GitLaw, HQ in Market St, San Francisco. Previously the founder of Whisk (acquired by Samsung), he now focuses on creating AI tools that remove friction from everyday work. Previous to Whisk, Nick founded two other businesses. In 2017, Nick was awarded an honorary doctorate from Aston University. Nick is regularly featured in leading news publications and featured in the BBC Apprentice 2012, where he got to the final with the series's best task-win record. He lives in the UK with his wife Priyanka and their two children.
